{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>weight1</th>\n",
       "      <th>history</th>\n",
       "      <th>HB</th>\n",
       "      <th>IFA</th>\n",
       "      <th>BP1</th>\n",
       "      <th>education</th>\n",
       "      <th>res</th>\n",
       "      <th>reslt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.168317</td>\n",
       "      <td>23.734043</td>\n",
       "      <td>45.280899</td>\n",
       "      <td>1.103093</td>\n",
       "      <td>9.053659</td>\n",
       "      <td>0.702970</td>\n",
       "      <td>1.705637</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.131313</td>\n",
       "      <td>0.742574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.217122</td>\n",
       "      <td>3.150160</td>\n",
       "      <td>7.849826</td>\n",
       "      <td>0.699779</td>\n",
       "      <td>0.783734</td>\n",
       "      <td>0.459229</td>\n",
       "      <td>1.298492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336050</td>\n",
       "      <td>0.439397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.053659</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.571000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.705637</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.875000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          age     weight1     history          HB         IFA  \\\n",
       "count  101.000000  101.000000  101.000000  101.000000  101.000000  101.000000   \n",
       "mean     2.168317   23.734043   45.280899    1.103093    9.053659    0.702970   \n",
       "std      1.217122    3.150160    7.849826    0.699779    0.783734    0.459229   \n",
       "min      1.000000   17.000000   30.000000    1.000000    5.900000    0.000000   \n",
       "25%      1.000000   21.000000   40.000000    1.000000    9.000000    0.000000   \n",
       "50%      2.000000   24.000000   45.000000    1.000000    9.053659    1.000000   \n",
       "75%      3.000000   25.000000   50.000000    1.000000    9.200000    1.000000   \n",
       "max      4.000000   38.000000   65.000000    6.000000   11.000000    1.000000   \n",
       "\n",
       "              BP1  education         res       reslt  \n",
       "count  101.000000      101.0  101.000000  101.000000  \n",
       "mean     1.705637        5.0    1.131313    0.742574  \n",
       "std      1.298492        0.0    0.336050    0.439397  \n",
       "min      1.200000        5.0    1.000000    0.000000  \n",
       "25%      1.375000        5.0    1.000000    0.000000  \n",
       "50%      1.571000        5.0    1.000000    1.000000  \n",
       "75%      1.705637        5.0    1.000000    1.000000  \n",
       "max     13.875000        5.0    2.000000    1.000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Andhra_dataset2.csv\")\n",
    "df[[\"BP1\"]] = df[[\"BP1\"]].astype(\"float\")\n",
    "df = df.groupby(df.columns, axis = 1).transform(lambda x: x.fillna(x.mean()))\n",
    "#why?\n",
    "df[\"BP1\"] = df[\"BP1\"].fillna(df.BP1.mean())\n",
    "df.describe()\n",
    "df.isna().sum()\n",
    "df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' ', 'age', 'weight1', 'history', 'HB', 'IFA', 'BP1', 'education',\n",
       "       'res', 'reslt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of 'prefix' (1) did not match the length of the columns being encoded (0).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-49502336a824>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitxy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msplitxy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-49502336a824>\u001b[0m in \u001b[0;36msplitxy\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msplitxy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reslt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'history'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'IFA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    823\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m         \u001b[0mcheck_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'prefix'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m         \u001b[0mcheck_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix_sep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'prefix_sep'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mcheck_len\u001b[1;34m(item, name)\u001b[0m\n\u001b[0;32m    821\u001b[0m                     len_msg = len_msg.format(name=name, len_item=len(item),\n\u001b[0;32m    822\u001b[0m                                              len_enc=data_to_encode.shape[1])\n\u001b[1;32m--> 823\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m         \u001b[0mcheck_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'prefix'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of 'prefix' (1) did not match the length of the columns being encoded (0)."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "def splitxy(df):\n",
    "    x = df[df.columns.difference(['reslt'])]\n",
    "    df = pd.get_dummies(df,prefix=[' '], drop_first=True)\n",
    "    df = pd.get_dummies(df,prefix=['history'], drop_first=True)\n",
    "    df = pd.get_dummies(df,prefix=['IFA'], drop_first=True)\n",
    "    df = pd.get_dummies(df,prefix=['res'], drop_first=True)\n",
    "    y = df[\"reslt\"]\n",
    "    return x,y\n",
    "\n",
    "x_train, y_train = splitxy(train)\n",
    "x_test , y_test  = splitxy(test)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, max_depth=5,\n",
    "                          random_state=0)\n",
    "clf1 = GradientBoostingClassifier(n_estimators = 100, random_state = 0)\n",
    "clf.fit(x_train,y_train)\n",
    "clf1.fit(x_train, y_train)\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "print(accuracy_score(clf1.predict(x_test), y_test))\n",
    "accuracy_score(clf.predict(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of 'prefix' (1) did not match the length of the columns being encoded (0).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-3336aed5e71f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitxy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mx_test\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msplitxy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-15874dfeebc2>\u001b[0m in \u001b[0;36msplitxy\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msplitxy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reslt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'history'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'IFA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    823\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m         \u001b[0mcheck_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'prefix'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m         \u001b[0mcheck_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix_sep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'prefix_sep'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mcheck_len\u001b[1;34m(item, name)\u001b[0m\n\u001b[0;32m    821\u001b[0m                     len_msg = len_msg.format(name=name, len_item=len(item),\n\u001b[0;32m    822\u001b[0m                                              len_enc=data_to_encode.shape[1])\n\u001b[1;32m--> 823\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m         \u001b[0mcheck_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'prefix'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of 'prefix' (1) did not match the length of the columns being encoded (0)."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "kf = KFold(n_splits=5)\n",
    "gbdt = []\n",
    "rf = []\n",
    "ada = []\n",
    "dnn = []\n",
    "knn = []\n",
    "nb = []\n",
    "kf.get_n_splits(df)\n",
    "for train_index, test_index in kf.split(df):\n",
    "    \n",
    "    \n",
    "    train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "    x_train, y_train = splitxy(train)\n",
    "    x_test , y_test  = splitxy(test)\n",
    "    scaler = MinMaxScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    clf = RandomForestClassifier( max_depth=2)\n",
    "    clf1 = GradientBoostingClassifier()\n",
    "    clf2 = AdaBoostClassifier(n_estimators = 100)\n",
    "    clf3 = MLPClassifier(solver='lbfgs', alpha=1e-3,\n",
    "                    hidden_layer_sizes=(5, 5 ,5 , 2))\n",
    "    neigh = KNeighborsClassifier(n_neighbors=6)\n",
    "    mnb = MultinomialNB()\n",
    "    \n",
    "    neigh.fit(x_train, y_train) \n",
    "    clf.fit(x_train,y_train)\n",
    "    clf1.fit(x_train, y_train)\n",
    "    clf2.fit(x_train, y_train)\n",
    "    clf3.fit(x_train, y_train)\n",
    "    mnb.fit(x_train, y_train)\n",
    "    \n",
    "    dnn.append(accuracy_score(clf3.predict(x_test), y_test))\n",
    "    gbdt.append(accuracy_score(clf1.predict(x_test), y_test))\n",
    "    rf.append(accuracy_score(clf.predict(x_test), y_test))\n",
    "    ada.append(accuracy_score(clf.predict(x_test), y_test))\n",
    "    knn.append(accuracy_score(neigh.predict(x_test), y_test))\n",
    "    nb.append(accuracy_score(mnb.predict(x_test), y_test))\n",
    "    \n",
    "print(\"gbdt\", sum(gbdt)/len(gbdt), gbdt)\n",
    "print(\"random forest\",sum(rf)/len(rf), rf)\n",
    "print(\"adaboost\",sum(ada)/len(ada), ada)\n",
    "print(\"neural network\", sum(dnn)/len(dnn), dnn)\n",
    "print(\"knn\", sum(knn)/len(knn), knn)\n",
    "print(\"mnb\", sum(nb)/len(nb), nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66666667, 0.11953488, 0.60784314, 1.        , 0.33333333,\n",
       "        0.        , 0.        , 0.        , 0.71428571],\n",
       "       [0.66666667, 0.11960133, 0.58823529, 0.        , 0.14285714,\n",
       "        0.        , 0.        , 1.        , 0.43659711],\n",
       "       [0.        , 0.08637874, 0.64705882, 1.        , 0.42857143,\n",
       "        0.        , 0.        , 0.        , 0.14285714],\n",
       "       [0.        , 0.04069767, 0.60784314, 1.        , 0.38095238,\n",
       "        0.        , 0.        , 0.        , 0.34285714],\n",
       "       [1.        , 0.04069767, 0.49019608, 1.        , 0.33333333,\n",
       "        0.        , 0.        , 0.        , 0.57142857],\n",
       "       [1.        , 0.04069767, 0.60784314, 1.        , 0.42857143,\n",
       "        0.        , 0.        , 1.        , 1.        ],\n",
       "       [0.        , 0.10852713, 0.39215686, 0.        , 0.19047619,\n",
       "        0.        , 0.        , 0.        , 0.28571429],\n",
       "       [0.66666667, 0.11758999, 0.61836442, 0.        , 0.33333333,\n",
       "        0.        , 0.        , 0.        , 0.28571429],\n",
       "       [0.        , 0.04069767, 0.62745098, 0.        , 0.38095238,\n",
       "        0.        , 0.        , 0.        , 0.31428571],\n",
       "       [0.        , 2.94767442, 0.56862745, 1.        , 0.19047619,\n",
       "        0.        , 0.        , 1.        , 0.62857143],\n",
       "       [0.        , 0.08627907, 0.64705882, 1.        , 0.42857143,\n",
       "        0.        , 0.        , 0.        , 0.14285714],\n",
       "       [0.66666667, 0.08637874, 0.62745098, 0.        , 0.38095238,\n",
       "        0.        , 0.        , 0.        , 0.54285714],\n",
       "       [0.66666667, 0.08637874, 0.78431373, 1.        , 0.85714286,\n",
       "        0.        , 0.        , 0.        , 0.43659711],\n",
       "       [0.66666667, 0.11758999, 0.61836442, 0.        , 0.33333333,\n",
       "        0.        , 0.        , 0.        , 0.22857143],\n",
       "       [0.        , 0.04069767, 0.60784314, 1.        , 0.42857143,\n",
       "        0.        , 0.        , 0.        , 0.42857143],\n",
       "       [0.66666667, 0.04069767, 0.60784314, 1.        , 0.19047619,\n",
       "        0.        , 0.        , 0.        , 0.28571429],\n",
       "       [1.        , 0.04069767, 0.98039216, 0.        , 0.19047619,\n",
       "        0.        , 0.        , 0.        , 0.85714286],\n",
       "       [0.66666667, 0.04069767, 0.60784314, 0.        , 0.19047619,\n",
       "        0.        , 0.        , 0.        , 0.71428571],\n",
       "       [1.        , 0.08637874, 0.96078431, 1.        , 0.04761905,\n",
       "        0.        , 0.        , 0.        , 0.6       ],\n",
       "       [0.        , 0.04069767, 0.64705882, 1.        , 0.38095238,\n",
       "        0.        , 0.        , 0.        , 0.28571429]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pradyumna\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Pradyumna\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7666666666666666\n",
      "[0.3333333333333333, 0.95, 1.0, 0.85, 0.7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "lgbm_params =  {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'nthread': 8,\n",
    "    'learning_rate': 0.02,\n",
    "    'bagging_fraction': 1,\n",
    "    'num_rounds':300\n",
    "    }\n",
    "\n",
    "\n",
    "df['reslt'] = df['reslt'].astype(int)\n",
    "kf = KFold(n_splits=5)\n",
    "gbdt = []\n",
    "rf = []\n",
    "ada = []\n",
    "kf.get_n_splits(df)\n",
    "for train_index, test_index in kf.split(df):\n",
    "    train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "    x_train, y_train = splitxy(train)\n",
    "    x_test , y_test  = splitxy(test)\n",
    "    dtrain = lgb.Dataset(x_train, y_train, silent = False, categorical_feature = [\"IFA\", \"res\", \"education\" ])\n",
    "    model = lgb.train(lgbm_params, train_set = dtrain)\n",
    "    gbdt.append(accuracy_score(np.round(model.predict(x_test)), y_test))\n",
    "print(sum(gbdt)/len(gbdt))\n",
    "print(gbdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>weight1</th>\n",
       "      <th>history</th>\n",
       "      <th>HB</th>\n",
       "      <th>IFA</th>\n",
       "      <th>BP1</th>\n",
       "      <th>education</th>\n",
       "      <th>res</th>\n",
       "      <th>reslt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.168317</td>\n",
       "      <td>23.734043</td>\n",
       "      <td>45.280899</td>\n",
       "      <td>1.103093</td>\n",
       "      <td>9.053659</td>\n",
       "      <td>0.702970</td>\n",
       "      <td>1.705637</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.131313</td>\n",
       "      <td>0.742574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.217122</td>\n",
       "      <td>3.150160</td>\n",
       "      <td>7.849826</td>\n",
       "      <td>0.699779</td>\n",
       "      <td>0.783734</td>\n",
       "      <td>0.459229</td>\n",
       "      <td>1.298492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336050</td>\n",
       "      <td>0.439397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.053659</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.571000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.705637</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.875000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          age     weight1     history          HB         IFA  \\\n",
       "count  101.000000  101.000000  101.000000  101.000000  101.000000  101.000000   \n",
       "mean     2.168317   23.734043   45.280899    1.103093    9.053659    0.702970   \n",
       "std      1.217122    3.150160    7.849826    0.699779    0.783734    0.459229   \n",
       "min      1.000000   17.000000   30.000000    1.000000    5.900000    0.000000   \n",
       "25%      1.000000   21.000000   40.000000    1.000000    9.000000    0.000000   \n",
       "50%      2.000000   24.000000   45.000000    1.000000    9.053659    1.000000   \n",
       "75%      3.000000   25.000000   50.000000    1.000000    9.200000    1.000000   \n",
       "max      4.000000   38.000000   65.000000    6.000000   11.000000    1.000000   \n",
       "\n",
       "              BP1  education         res       reslt  \n",
       "count  101.000000      101.0  101.000000  101.000000  \n",
       "mean     1.705637        5.0    1.131313    0.742574  \n",
       "std      1.298492        0.0    0.336050    0.439397  \n",
       "min      1.200000        5.0    1.000000    0.000000  \n",
       "25%      1.375000        5.0    1.000000    0.000000  \n",
       "50%      1.571000        5.0    1.000000    1.000000  \n",
       "75%      1.705637        5.0    1.000000    1.000000  \n",
       "max     13.875000        5.0    2.000000    1.000000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
